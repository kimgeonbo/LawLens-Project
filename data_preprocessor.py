import re
import emoji
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
import json

load_dotenv()

class LawLensPreprocessor:
    def __init__(self):
        # ë¶„ì„ì„ ìœ„í•œ LLM ì„¤ì •
        self.llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

    # ---------------------------------------------------------
    # ì •ê·œí™” (Normalization) & ë…¸ì´ì¦ˆ ì œê±° (Noise Cleaning)
    # íŒŒì´ì¬ ì •ê·œì‹ ì‚¬ìš©
    # ---------------------------------------------------------
    def clean_text(self, text):
        if not text:
            return ""
        # 1. ë‚ ì§œ/ì‹œê°„ íŒ¨í„´ ê°•í™” (ë‹¤ì–‘í•œ í¬ë§· ëŒ€ì‘)
        # ì˜ˆ: "2024ë…„ 1ì›” 1ì¼ ì›”ìš”ì¼", "---- 2024.01.01 ----", "[ì˜¤ì „ 10:30]", "14:20:55" ë“±
        text = re.sub(r'[-=]*\s*\d{4}[ë…„.-]\s*\d{1,2}[ì›”.-]\s*\d{1,2}[ì¼.-]?\s*.*[-=]*', '', text) # ë‚ ì§œ êµ¬ë¶„ì„  ì œê±°
        text = re.sub(r'\[?\s*(ì˜¤ì „|ì˜¤í›„)?\s*\d{1,2}:\d{2}(:\d{2})?\s*\]?', '', text)  # íƒ€ì„ìŠ¤íƒ¬í”„ í†µí•© ì œê±°

        # 2. ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œê±° (ì¤„ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ì•ˆì „ì„± í™•ë³´)
        # ".*" íŒ¨í„´ì€ ìì¹« ì¼ë°˜ ëŒ€í™”ê¹Œì§€ ì§€ìš¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¤„ì˜ ì‹œì‘(^)ê³¼ ë($)ì„ ëª…ì‹œí•˜ê±°ë‚˜ íŠ¹ì • í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ì‚­ì œ
        system_patterns = [
            r'.*ë‹˜ì´ ì…ì¥í•˜ì…¨ìŠµë‹ˆë‹¤.*',
            r'.*ë‹˜ì´ ë‚˜ê°”ìŠµë‹ˆë‹¤.*',
            r'.*ë‹˜ì´ .*ë‹˜ì„ ì´ˆëŒ€í–ˆìŠµë‹ˆë‹¤.*',
            r'.*ì±„íŒ…ë°©ì„ ë‚˜ê°”ìŠµë‹ˆë‹¤.*'
        ]
        for pattern in system_patterns:
            text = re.sub(pattern, '', text)
        # 3. ê°œì¸ì •ë³´(PII) ë§ˆìŠ¤í‚¹
        # ì „í™”ë²ˆí˜¸ (010-1234-5678, 010 1234 5678) -> [ì „í™”ë²ˆí˜¸]
        text = re.sub(r'01[016789][-\s.]?\d{3,4}[-\s.]?\d{4}', '[ì „í™”ë²ˆí˜¸]', text)

        # 4. ë°˜ë³µ ë¬¸ì ì¶•ì•½ 
        text = re.sub(r'(.)\1{2,}', r'\1\1', text)

        # 5. ì´ëª¨ì§€ ë³€í™˜ ì‹œ ë„ì–´ì“°ê¸° í™•ë³´
        # ì´ëª¨ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë°”ê¿€ ë•Œ ì•ë’¤ ê³µë°±ì„ ë„£ì–´ ë¶„ì„ê¸°ê°€ ë‹¨ì–´ë¥¼ ì˜ êµ¬ë¶„í•˜ê²Œ í•¨
        text = emoji.demojize(text, language='ko')
        text = text.replace(":", " ") # :smile: -> smile (ì½œë¡  ì œê±°ë¡œ í† í°í™” ìš©ì´í•˜ê²Œ)

        # 6. ë‹¤ì¤‘ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì •ë¦¬
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì‚­ì œ í›„ ë‚¨ì€ "  " ë“±ì„ ê³µë°± í•˜ë‚˜ë¡œ í†µì¼
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    # ---------------------------------------------------------
    # ë²•ë¥ ì  íŒë‹¨ ë° êµ¬ì¡°í™”
    # ê·œì¹™ìœ¼ë¡œ ì§œê¸° ì–´ë ¤ìš´ 'ë§¥ë½'ì€ LLMì—ê²Œ ì‹œí‚´
    # ---------------------------------------------------------
    def analyze_features(self, cleaned_text):
        prompt = PromptTemplate.from_template("""
        ë„ˆëŠ” ì‚¬ì´ë²„ ë²”ì£„ ì „ë¬¸ ë²•ë¥  ë¶„ì„ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´.
        
        [ë¶„ì„í•  í…ìŠ¤íŠ¸]
        {text}

        [ë¶„ì„ ì§€ì¹¨]
        1. ëŒ€ìƒ íŠ¹ì •ì„± (target_type): ê°œì¸(ë‹‰ë„¤ì„), ê°œì¸(ì‹¤ëª…/ì§€ì¸), ì§‘ë‹¨, ë¶ˆíŠ¹ì • ì¤‘ ì„ íƒ
        2. ê³µì—°ì„± (space): 1:1ëŒ€í™”, ì†Œìˆ˜ë‹¨í†¡ë°©, ë‹¤ìˆ˜ë‹¨í†¡ë°©, ì „ì²´ì±„íŒ…/ê²Œì‹œíŒ ì¤‘ ì„ íƒ
        3. í‘œí˜„ ìœ í˜• (expression): ë‹¨ìˆœìš•ì„¤, ì¸ê²©ë¹„í•˜, ì„±ì í‘œí˜„, íŒ¨ë“œë¦½, í˜‘ë°•, ì‚¬ì‹¤ì ì‹œ ì¤‘ ì„ íƒ (ë³µìˆ˜ ê°€ëŠ¥)
        4. ëª©ì ì„± (sexual_intent): ì—†ìŒ, ë¶„ë…¸í‘œì¶œ, ì„±ì í¥ë¶„/ë§Œì¡±, ì¡°ë¡± ì¤‘ ì„ íƒ (í†µë§¤ìŒ íŒë‹¨ í•µì‹¬)
        5. ë²”ì£„ ìœ í˜• í›„ë³´ (candidate_crime): ëª¨ìš•, í†µì‹ ë§¤ì²´ì´ìš©ìŒë€(í†µë§¤ìŒ), ëª…ì˜ˆí›¼ì†, í˜‘ë°•, ê¸°íƒ€ ì¤‘ ì„ íƒ
        6. ìœ„í—˜ë„ (risk_level): ë†’ìŒ, ì¤‘ê°„, ë‚®ìŒ, ì—†ìŒ
        7. STT/OCR ì˜¤íƒ€ ë³´ì • : "ë°•ì•„" vs "ë°–ì—", "ë³´ì§€" vs "ë³´ì§€ìš”" ë“± ë°œìŒì´ ìœ ì‚¬í•œ ì˜¤íƒ€ê°€ ìˆì–´ë„ ë¬¸ë§¥ì„ ë³´ê³  ì›ë˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ íŒë‹¨í•˜ì„¸ìš”.                    

        [ì¶œë ¥ í˜•ì‹ - ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•  ê²ƒ]
        {{
            "features": {{
                "target_type": "...",
                "space": "...",
                "expression": ["...", "..."],
                "sexual_intent": "..."
            }},
            "candidate_crime": "...",
            "risk_level": "...",
            "reason": "ê°„ë‹¨í•œ ë¶„ì„ ì´ìœ  í•œ ì¤„"
        }}
        """)

        chain = prompt | self.llm
        try:
            response = chain.invoke({"text": cleaned_text})
            # JSON ë¶€ë¶„ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ
            json_str = response.content.replace("```json", "").replace("```", "").strip()
            return json.loads(json_str)
        except Exception as e:
            return {"error": str(e), "candidate_crime": "ë¶„ì„ì‹¤íŒ¨"}

    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
    def run_pipeline(self, raw_text):
        # 1ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ì œ
        normalized_text = self.clean_text(raw_text)
        
        # 2ë‹¨ê³„: AI ì‹¬ì¸µ ë¶„ì„
        analysis_result = self.analyze_features(normalized_text)
        
        # 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ í•©ì¹˜ê¸°
        final_data = {
            "raw_text": raw_text,
            "normalized_text": normalized_text,
            "analysis": analysis_result
        }
        return final_data

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    processor = LawLensPreprocessor()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    sample = "[14:20] ê¹€ë¡¤ë¶•: ì•¼ì´ ì”¨%%%%ë°œ ê°œëª»ìƒê¸´ ë…„ì•„ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë‹ˆë„¤ ì—„ë§ˆí•œí…Œ ê°€ì„œ ì –ì´ë‚˜ ë” ë¨¹ê³ ì™€ë¼ ğŸ¤¬"
    
    result = processor.run_pipeline(sample)
    print(json.dumps(result, indent=2, ensure_ascii=False))