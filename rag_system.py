import os
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
DB_PATH = "./chroma_db"
EMBEDDING_MODEL = "models/gemini-embedding-001" 
LLM_MODEL = "gemini-2.5-flash"

def run_lawlens_analysis(query):
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key or not os.path.exists(DB_PATH):
        return {"result": "ì˜¤ë¥˜: API í‚¤ê°€ ì—†ê±°ë‚˜ DBê°€ ì—†ìŠµë‹ˆë‹¤.", "docs": [], "scores": []}
        
    embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
    vector_store = Chroma(
        persist_directory=DB_PATH, 
        embedding_function=embeddings,
        collection_name="lawlens_cases"
    )
    
    # 1. ë„‰ë„‰í•˜ê²Œ 10ê°œ ê²€ìƒ‰
    results = vector_store.similarity_search_with_relevance_scores(query, k=10)
    
    if not results:
        return {"result": "ì£„ì†¡í•©ë‹ˆë‹¤. ìœ ì‚¬í•œ íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "docs": [], "scores": []}

    # 2.ìœ ì£„/ë¬´ì£„ ë¶„ë¥˜
    guilty_cases = []
    other_cases = []
    
    for doc, score in results:
        judgment = doc.metadata.get("judgment", "")
        # ìœ ì£„ ì‹œê·¸ë„ í™•ì¸
        if "ìœ ì£„" in judgment or "ë²Œê¸ˆ" in judgment or "ì§•ì—­" in judgment or "ì„ ê³ ìœ ì˜ˆ" in judgment:
            guilty_cases.append((doc, score))
        else:
            other_cases.append((doc, score))

    # 3. ë©”ì¸ ì¼€ì´ìŠ¤ ì„ ì • ë° ìƒí™© íŒë‹¨
    is_guilty_found = False
    
    if guilty_cases:
        # ìœ ì£„ê°€ ìˆìœ¼ë©´ -> ê·¸ê±¸ ë©”ì¸ìœ¼ë¡œ (ì„±ê³µ!)
        main_case, main_score = guilty_cases[0]
        remaining = guilty_cases[1:] + other_cases
        is_guilty_found = True
        section_title = "ğŸ† ìœ ì‚¬ ìŠ¹ì†Œ ì‚¬ë¡€ (ìœ ì£„ íŒë¡€)"
        analysis_guide = "ì´ íŒë¡€ëŠ” ìœ ì£„ê°€ ì„ ê³ ëœ ì‚¬ë¡€ì…ë‹ˆë‹¤. ìŠ¹ì†Œ(ìœ ì£„) ìš”ì¸ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”."
    else:
        # ìœ ì£„ê°€ ì—†ìœ¼ë©´ -> ë¬´ì£„ ì¤‘ ì œì¼ ë¹„ìŠ·í•œ ê±¸ ë©”ì¸ìœ¼ë¡œ (ê²½ê³  ëª¨ë“œ!)
        main_case, main_score = results[0]
        remaining = results[1:]
        is_guilty_found = False
        section_title = "âš ï¸ ìœ ì‚¬ íŒë¡€ (ë¬´ì£„ ì‚¬ë¡€ ì£¼ì˜)"
        analysis_guide = """
        ğŸš¨ [ì¤‘ìš” ê²½ê³ ] ê²€ìƒ‰ ê²°ê³¼, ìœ ì‚¬í•œ ìœ ì£„ íŒë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. 
        ì´ ì‚¬ë¡€ëŠ” 'ë¬´ì£„(í˜ì˜ ì—†ìŒ)' íŒê²°ì´ ë‚œ ì‚¬ë¡€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì—ê²Œ 'ìœ ì‚¬í•œ ìŠ¹ì†Œ ì‚¬ë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŒ'ì„ ëª…í™•íˆ ì•Œë¦¬ê³ , 
        ì´ ì‚¬ê±´ì€ **ì–´ë–¤ ì´ìœ  ë•Œë¬¸ì— ì²˜ë²Œë°›ì§€ ì•Šì•˜ëŠ”ì§€(íŒ¨ì†Œ ìš”ì¸)**ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì£¼ì˜ë¥¼ ì£¼ì„¸ìš”.
        """

    # ìµœì¢… ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (ë©”ì¸ + ë‚˜ë¨¸ì§€ 4ê°œ)
    final_docs = [main_case]
    final_scores = [main_score]
    for doc, score in remaining[:4]:
        final_docs.append(doc)
        final_scores.append(score)

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    context_text = f"""
    [ğŸ“Œ ë©”ì¸ ë¶„ì„ ëŒ€ìƒ íŒë¡€]
    - íŒê²° ê²°ê³¼: {main_case.metadata.get('judgment')} (ë§¤ìš° ì¤‘ìš”!)
    - ì‚¬ê±´ë²ˆí˜¸: {main_case.metadata.get('case_id')}
    - ë‚´ìš©: {main_case.page_content}
    - ìœ ì‚¬ë„: {main_score*100:.1f}%

    [ğŸ“‘ ê¸°íƒ€ ì°¸ê³  íŒë¡€]
    """
    for i, doc in enumerate(final_docs[1:]):
        context_text += f"{i+1}. {doc.metadata.get('case_id')} ({doc.metadata.get('judgment')}): {doc.page_content[:100]}...\n"

    template = """
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì‚¬ì´ë²„ ë²”ì£„ ì „ë¬¸ AI ë³€í˜¸ì‚¬ 'LawLens'ì…ë‹ˆë‹¤.
    
    [ë¶„ì„ ë°ì´í„°]
    {context}

    [ì‚¬ìš©ì ìƒí™©]
    {question}

    **[AI ë¶„ì„ ê°€ì´ë“œ]**
    1. í˜„ì¬ ë¶„ì„ ëª¨ë“œ: **{section_title}**
    2. ì§€ì¹¨: {analysis_guide}
    3. ì‚¬ìš©ì ìƒí™©ì´ '[ë¶„ì„ ëª¨ë“œ: ê¸°ì‚¬/ì»¤ë®¤ë‹ˆí‹° ì•…í”Œ]'ì´ë©´ ì‘ì„±ìë³„ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„í•˜ì„¸ìš”.

    ---
    [ì‘ì„± ì–‘ì‹]

    ### 1. ğŸ“ AI ì‚¬ê±´ ì •ë°€ ë¶„ì„
    * **ì‚¬ê±´ ê°œìš”:** (ì „ì²´ì ì¸ ìƒí™© ìš”ì•½)
    * **í•µì‹¬ ìŸì :** (ëª¨ìš•ì„±, ê³µì—°ì„±, íŠ¹ì •ì„± ì¶©ì¡± ì—¬ë¶€)
    
    **(ë‹¤ì¤‘ ì•…í”Œì¸ ê²½ìš°ì—ë§Œ ì‘ì„±)**
    | ì‘ì„±ì | ë°œì–¸ ìš”ì•½ | ìš”ê±´ ì¶©ì¡±(ëª¨ìš•/íŠ¹ì •/ê³µì—°) | ì²˜ë²Œ í™•ë¥  |
    | :--- | :--- | :--- | :--- |
    | (ID) | (ë‚´ìš© ì§§ê²Œ) | ëª¨ìš•(O), íŠ¹ì •(X), ê³µì—°(O) | ë‚®ìŒ |
    | (ID) | (ë‚´ìš© ì§§ê²Œ) | ëª¨ìš•(O), íŠ¹ì •(O), ê³µì—°(O) | **ë§¤ìš° ë†’ìŒ** |

    **(ë‹¤ì¤‘ ì•…í”Œ ìƒì„¸ ë¶„ì„)**
    * **[ì‘ì„±ì ID 1] ìƒì„¸ ê²€í† :**
      - íŒë‹¨: (ì™œ ì²˜ë²Œ í™•ë¥ ì´ ë†’ì€ì§€/ë‚®ì€ì§€ êµ¬ì²´ì ì¸ ë²•ì  ì´ìœ  ì„œìˆ )
    * **[ì‘ì„±ì ID 2] ìƒì„¸ ê²€í† :**
      - íŒë‹¨: (ìš•ì„¤ì˜ ìˆ˜ìœ„, íŠ¹ì •ì„± ì„±ë¦½ ì—¬ë¶€ ë“± ìƒì„¸ ë¶„ì„)

    ### 2. {section_title}
    
    | êµ¬ë¶„ | ë‚´ìš© |
    | :--- | :--- |
    | **ìœ ì‚¬ë„** | **{main_score_str}** |
    | **ì‚¬ê±´ë²ˆí˜¸** | {main_case_id} |
    | **íŒê²° ê²°ê³¼** | **{main_judgment}** |
    | **ì‚¬ì‹¤ê´€ê³„** | (íŒë¡€ ë‚´ìš© ìš”ì•½) |
    | **ìŠ¹ì†Œ(ìœ ì£„) ìš”ì¸** | (ì´ ì‚¬ê±´ì—ì„œ ìœ ì£„ê°€ ì¸ì •ëœ ê²°ì •ì ì¸ ì´ìœ  1~2ê°€ì§€ / ë¬´ì£„ë¼ë©´ ë¬´ì£„ ì´ìœ ) |
    | **ë‚´ ì‚¬ê±´ê³¼ì˜ ê³µí†µì ** | (ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ì´ íŒë¡€ê°€ ìœ ì‚¬í•œ ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¹„êµ) |
    | **ë²•ì  íŒë‹¨ ê·¼ê±°** | (ë²•ì›ì˜ ë²•ë¥ ì  ë…¼ë¦¬ ë° ì ìš© ë²•ì¡°í•­) |
    | **ë‚´ ì‚¬ê±´ ì¡°ì–¸** | (ì´ íŒë¡€ë¥¼ í†µí•´ ë³¸ ë‚´ ì‚¬ê±´ì˜ ìœ ë¶ˆë¦¬ ë° ëŒ€ì‘ ì „ëµ) |

    ### 3. ğŸ“‘ ê¸°íƒ€ ìœ ì‚¬ íŒë¡€ ìš”ì•½
    (ì°¸ê³  íŒë¡€ 4ê±´ ìš”ì•½)
    * **ì‚¬ê±´ A:** (ì‚¬ê±´ëª…/ë²ˆí˜¸) - (ê²°ê³¼) / (í•µì‹¬ ì´ìœ )
    * **ì‚¬ê±´ B:** (ì‚¬ê±´ëª…/ë²ˆí˜¸) - (ê²°ê³¼) / (í•µì‹¬ ì´ìœ )
    * **ì‚¬ê±´ C:** (ì‚¬ê±´ëª…/ë²ˆí˜¸) - (ê²°ê³¼) / (í•µì‹¬ ì´ìœ )
    * **ì‚¬ê±´ D:** (ì‚¬ê±´ëª…/ë²ˆí˜¸) - (ê²°ê³¼) / (í•µì‹¬ ì´ìœ )

    ### 4. ğŸ“‰ ì˜ˆìƒ ì²˜ë²Œ ë° ìŠ¹ì†Œ í™•ë¥ 
    | êµ¬ë¶„ | ì˜ˆì¸¡ ê²°ê³¼ |
    | :--- | :--- |
    | **ìŠ¹ì†Œ í™•ë¥ ** | **{main_score_str}** (ìœ ì‚¬ íŒë¡€ ê¸°ë°˜) |
    | **ì˜ˆìƒ ë²Œê¸ˆ** | (ìœ ì£„ íŒë¡€ê°€ ì—†ìœ¼ë©´ 'ì˜ˆì¸¡ ë¶ˆê°€' ë˜ëŠ” 'ì²˜ë²Œ ê°€ëŠ¥ì„± ë‚®ìŒ'ìœ¼ë¡œ ê¸°ì¬) |
    | **ì²˜ë²Œ ìˆ˜ìœ„** | (ì˜ˆìƒë˜ëŠ” ì²˜ë¶„) |

    ### 5. ğŸ›ï¸ ê³ ì†Œ ì ˆì°¨ ì•ˆë‚´
    (í‘œì¤€ ì ˆì°¨ ì•ˆë‚´)
    * **í‘œì¤€ ì ˆì°¨:** ê²½ì°°ì„œ ì ‘ìˆ˜(ê³ ì†Œì¥) -> í”¼ì˜ì íŠ¹ì • ë° ì†Œí™˜ ì¡°ì‚¬ -> ê²€ì°° ì†¡ì¹˜ -> ê¸°ì†Œ -> ë²•ì› íŒê²°
    * **ì˜ˆìƒ ì†Œìš” ì‹œê°„:** (í†µìƒì ì¸ ì‚¬ì´ë²„ ëª¨ìš•ì£„ ì‚¬ê±´ ì†Œìš” ì‹œê°„, ì˜ˆ: 3~6ê°œì›”)
    * **ì¤€ë¹„ë¬¼:** ì‹ ë¶„ì¦, ì¦ê±° ìë£Œ(ìº¡ì²˜, ë…¹ìŒ ë“±), ê³ ì†Œì¥

    ---
    **ì‘ì„± ì§€ì¹¨:** - ë§Œì•½ 'ë¬´ì£„ ì‚¬ë¡€ ì£¼ì˜' ëª¨ë“œë¼ë©´, ìŠ¹ì†Œ í™•ë¥ ì´ ë‚®ì„ ìˆ˜ ìˆìŒì„ ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.
    - í‘œ í˜•ì‹ì„ ë°˜ë“œì‹œ ìœ ì§€í•˜ì„¸ìš”.
    """
    
    prompt = PromptTemplate(template=template, input_variables=[
        "context", "question", "main_score_str", "main_case_id", 
        "section_title", "analysis_guide", "main_judgment"
    ])
    
    llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.1, google_api_key=api_key)
    chain = prompt | llm | StrOutputParser()
    
    final_response = chain.invoke({
        "context": context_text,
        "question": query,
        "main_score_str": f"ì•½ {main_score*100:.1f}%",
        "main_case_id": main_case.metadata.get('case_id', 'ì •ë³´ ì—†ìŒ'),
        "main_judgment": main_case.metadata.get('judgment', 'ë¯¸ìƒ'),
        "section_title": section_title,
        "analysis_guide": analysis_guide
    })
    
    return {
        "result": final_response,
        "docs": final_docs,
        "scores": final_scores
    }

# (í˜¸í™˜ì„± ìœ ì§€)
def get_lawlens_advisor(): pass
def get_similarity_scores(query, k=5): pass

def generate_complaint_draft(user_story):
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key: return "API Key Error"
    llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.2, google_api_key=api_key)
    prompt = PromptTemplate(template="[ì‚¬ìš©ì ìƒí™©]\n{story}\n\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê²½ì°°ì²­ í‘œì¤€ ê³ ì†Œì¥ ë‚´ìš©ì„ ì‘ì„±í•´ì¤˜.", input_variables=["story"])
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"story": user_story})